{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Run this notebook in classic SageMaker notebooks. Do NOT use SageMaker Studio notebook. You can also execute the commands locally from your desktop terminal if it is setup with AWS credentials.\n",
    "\n",
    "Use `conda_python3` kernel if using SageMaker classic notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a docker image locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  99.33kB\n",
      "Step 1/13 : ARG FUNCTION_DIR=\"/function\"\n",
      "Step 2/13 : FROM python:3.7-slim\n",
      " ---> b5900b90787e\n",
      "Step 3/13 : RUN apt-get update  && apt-get install unixodbc -y  && apt-get install unixodbc-dev -y  && apt-get install freetds-dev -y  && apt-get install freetds-bin -y  && apt-get install tdsodbc -y  && apt-get install --reinstall build-essential -y\n",
      " ---> Using cache\n",
      " ---> 1c880f72312b\n",
      "Step 4/13 : RUN echo \"[FreeTDS]\\nDescription = FreeTDS unixODBC Driver\\nDriver = /usr/lib/x86_64-linux-gnu/odbc/libtdsodbc.so\\nSetup = /usr/lib/x86_64-linux-gnu/odbc/libtdsS.so\" >> /etc/odbcinst.ini\n",
      " ---> Using cache\n",
      " ---> 5e8819a57dc6\n",
      "Step 5/13 : ARG FUNCTION_DIR\n",
      " ---> Using cache\n",
      " ---> 96bc47ca9566\n",
      "Step 6/13 : RUN mkdir -p ${FUNCTION_DIR}\n",
      " ---> Using cache\n",
      " ---> fc542d6d04ec\n",
      "Step 7/13 : WORKDIR ${FUNCTION_DIR}\n",
      " ---> Using cache\n",
      " ---> 71eb5f753638\n",
      "Step 8/13 : COPY app/* ${FUNCTION_DIR}/\n",
      " ---> Using cache\n",
      " ---> 309a21478397\n",
      "Step 9/13 : COPY requirements.txt ${FUNCTION_DIR}/\n",
      " ---> Using cache\n",
      " ---> 0c611977bd9b\n",
      "Step 10/13 : RUN python3 -m pip install --no-cache-dir -r ${FUNCTION_DIR}/requirements.txt\n",
      " ---> Using cache\n",
      " ---> dadf1a7e4433\n",
      "Step 11/13 : RUN python3 -m pip install awslambdaric\n",
      " ---> Using cache\n",
      " ---> ecc9ff645374\n",
      "Step 12/13 : ENTRYPOINT [ \"/usr/local/bin/python3\", \"-m\", \"awslambdaric\" ]\n",
      " ---> Using cache\n",
      " ---> 36e761bd6373\n",
      "Step 13/13 : CMD [ \"app.handler\" ]\n",
      " ---> Using cache\n",
      " ---> 1dfd47b31c66\n",
      "Successfully built 1dfd47b31c66\n",
      "Successfully tagged pyodbc-sage:latest\n"
     ]
    }
   ],
   "source": [
    "!docker build -t pyodbc-sage -f Dockerfile ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push local docker image to AWS Elastic Container Registry (ECR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container Name:  pyodbc-sage\n",
      "Account:  892313895307\n",
      "Region: us-east-1\n",
      "ECR Repository:  892313895307.dkr.ecr.us-east-1.amazonaws.com\n",
      "ECR Image URI:  892313895307.dkr.ecr.us-east-1.amazonaws.com/pyodbc-sage:latest\n",
      "Login Succeeded\n",
      "The push refers to repository [892313895307.dkr.ecr.us-east-1.amazonaws.com/pyodbc-sage]\n",
      "61e0a59b7d8f: Preparing\n",
      "3e43e4c5a17e: Preparing\n",
      "5cc48df952e1: Preparing\n",
      "83c8d6c843ab: Preparing\n",
      "68e9c1bfdd62: Preparing\n",
      "8ac03f2907c0: Preparing\n",
      "d57d30b7f01f: Preparing\n",
      "e8f55de3cd48: Preparing\n",
      "f70d531659d0: Preparing\n",
      "a2bef98ac977: Preparing\n",
      "53264a515eac: Preparing\n",
      "814bff734324: Preparing\n",
      "a2bef98ac977: Waiting\n",
      "8ac03f2907c0: Waiting\n",
      "53264a515eac: Waiting\n",
      "d57d30b7f01f: Waiting\n",
      "814bff734324: Waiting\n",
      "e8f55de3cd48: Waiting\n",
      "f70d531659d0: Waiting\n",
      "68e9c1bfdd62: Layer already exists\n",
      "61e0a59b7d8f: Layer already exists\n",
      "5cc48df952e1: Layer already exists\n",
      "83c8d6c843ab: Layer already exists\n",
      "3e43e4c5a17e: Layer already exists\n",
      "8ac03f2907c0: Layer already exists\n",
      "e8f55de3cd48: Layer already exists\n",
      "d57d30b7f01f: Layer already exists\n",
      "f70d531659d0: Layer already exists\n",
      "a2bef98ac977: Layer already exists\n",
      "53264a515eac: Layer already exists\n",
      "814bff734324: Layer already exists\n",
      "latest: digest: sha256:f0851ff870bbd590294da580388da7112cfe35e762eaa82c051d3661a69a1f0f size: 2834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# Specify a name to your custom container\n",
    "container_name=pyodbc-sage # make sure this name is same as the image name above\n",
    "echo \"Container Name: \" ${container_name}\n",
    "\n",
    "# Retrieve AWS account ID\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the AWS region defined in the current configuration (default to us-east-1 if not defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-east-1}\n",
    "\n",
    "echo \"Account: \" ${account}\n",
    "echo \"Region: \"${region}\n",
    "\n",
    "repository=\"${account}.dkr.ecr.${region}.amazonaws.com\"\n",
    "echo \"ECR Repository: \" ${repository}\n",
    "\n",
    "image=\"${account}.dkr.ecr.${region}.amazonaws.com/${container_name}:latest\"\n",
    "echo \"ECR Image URI: \" ${image}\n",
    "\n",
    "# If the ECR repository does not exist, create it.\n",
    "aws ecr describe-repositories --repository-names ${container_name} > /dev/null 2>&1\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "aws ecr create-repository --repository-name ${container_name} > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "aws ecr get-login-password --region ${region} | docker login --username AWS --password-stdin ${repository}\n",
    "\n",
    "# Tag the local image with ECR image name\n",
    "docker tag ${container_name} ${image}\n",
    "\n",
    "# Finally, push the local docker image to ECR with the full ECR image name\n",
    "docker push ${image}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
